## **OTT-Navi: 통합 사용자 가이드 (실행 및 사용편)**

이 가이드는 개발 환경이 준비되었다는 가정 하에, Docker 컨테이너를 실행하고, 데이터를 구축하며, 최종적으로 Streamlit 애플리케이션을 통해 개인화 추천을 받는 전 과정을 상세히 안내합니다.

### **목차**

1. **[1단계: 프로젝트 환경 설정]** 1.1. Python 가상환경 설정 및 라이브러리 설치 1.2. Google API 인증 정보 설정 1.3. MovieLens 데이터셋 준비
    
2. **[2단계: 시스템 빌드 및 데이터 구축]** 2.1. 데이터베이스 서버 실행 (`docker-compose`) 2.2. DB 스키마 생성 및 데이터 적재 2.3. 기본 OTT 플랫폼 목록 등록 2.4. (선택) 전체 영화 OTT 정보 업데이트
    
3. **[3단계: 서비스 실행 및 추천 받기]** 3.1. Streamlit 애플리케이션 실행 3.2. 추천 워크플로우: 설문부터 최종 결과까지
    
4. **[4단계: 문제 해결 가이드]** 4.1. 자주 발생하는 오류 및 해결 방법
    

---

### **1단계: 프로젝트 환경 설정**

본격적인 실행에 앞서, 프로젝트가 외부 서비스와 연동하고 필요한 데이터를 읽을 수 있도록 몇 가지 중요한 설정을 진행해야 합니다.

#### **1.1. Python 가상환경 설정 및 라이브러리 설치**

프로젝트의 독립적인 실행 환경을 보장하기 위해 Python 가상환경을 사용합니다.

1. **가상환경 생성 및 활성화**
    
    - 프로젝트의 최상위 폴더(`OTT_recommend`)에서 터미널을 열고, 아래 명령어를 입력하여 `venv`라는 이름의 가상환경을 생성하고 활성화합니다.
        
    - **Windows**:
        
        Bash
        
        ```
        python -m venv venv
        .\venv\Scripts\activate
        ```
        
    - **Mac/Linux**:
        
        Bash
        
        ```
        python -m venv venv
        source venv/bin/activate
        ```
        
    - 성공적으로 활성화되면 터미널의 프롬프트(입력 커서 앞)에 `(venv)` 라는 표시가 나타납니다. 앞으로 모든 `python` 및 `pip` 명령어는 이 가상환경 내에서 실행됩니다.
        
2. **필수 라이브러리 설치**
    
    - `app/requirements.txt` 파일에는 프로젝트 실행에 필요한 모든 파이썬 라이브러리 목록이 정의되어 있습니다. 아래 명령어를 통해 한 번에 설치를 진행합니다.
        
        Bash
        
        ```
        pip install -r app/requirements.txt
        ```
        
    - 설치가 진행되며 여러 라이브러리 이름이 터미널에 표시됩니다. 최종적으로 `Successfully installed ...` 와 유사한 메시지가 출력되면 모든 라이브러리가 성공적으로 설치된 것입니다.
        

#### **1.2. Google API 인증 정보 설정**

영화별 OTT 서비스 정보를 실시간으로 조회하기 위해 Google의 맞춤 검색(Custom Search) API를 사용합니다. 이를 위한 인증 정보를 프로젝트에 등록해야 합니다.

1. **Google Cloud Platform(GCP)에서 API 키 발급받기**
    
    - [Google Cloud Console](https://console.cloud.google.com/)에 로그인 후, 새 프로젝트를 생성합니다.
        
    - 좌측 메뉴에서 `API 및 서비스` > `라이브러리`로 이동합니다.
        
    - 검색창에 `Custom Search API`를 검색하여 선택하고 `사용 설정` 버튼을 클릭합니다.
        
    - 다시 `API 및 서비스` > `사용자 인증 정보`로 이동하여 `+ 사용자 인증 정보 만들기` > `API 키`를 선택합니다.
        
    - 생성된 **API 키** 문자열을 복사하여 안전한 곳에 보관합니다.
        
2. **Programmable Search Engine(PSE)에서 검색 엔진 ID 발급받기**
    
    - [Programmable Search Engine](https://programmablesearchengine.google.com/) 사이트로 이동하여 `추가` 버튼을 클릭해 새 검색 엔진을 생성합니다.
        
    - '검색할 사이트'에는 `www.google.com`을 입력하고, '이미지 검색'과 '세이프서치'는 활성화한 뒤, 검색 엔진 이름을 정하고 '만들기'를 클릭합니다.
        
    - 생성된 검색 엔진의 `수정` > `기본` 탭으로 이동하면 **검색 엔진 ID**를 확인할 수 있습니다. 이 ID를 복사하여 보관합니다.
        
3. `.env` 파일 생성 및 인증 정보 입력
    
    - 프로젝트의 `app/env/` 폴더 내에 `.env` 라는 이름의 새 파일을 생성합니다. (만약 `credentials.json`을 사용하신다면 해당 파일을 수정합니다.)
        
    - 아래와 같은 형식으로, 위에서 발급받은 키와 ID를 파일에 입력하고 저장합니다.
        
        코드 스니펫
        
        ```
        # 파일 경로: app/env/.env
        
        GOOGLE_API_KEY="여기에-발급받은-API-키를-붙여넣으세요"
        GOOGLE_CSE_ID="여기에-발급받은-검색-엔진-ID를-붙여넣으세요"
        ```
        
    - **보안 참고**: `.env` 파일은 민감한 개인 인증 정보를 담고 있으므로, Git과 같은 버전 관리 시스템에 포함되지 않도록 `.gitignore` 파일에 `app/env/.env` 경로가 추가되어 있는지 항상 확인해야 합니다.
        

#### **1.3. MovieLens 데이터셋 준비**

추천 시스템의 근간이 되는 초기 데이터를 준비합니다.

1. **데이터셋 다운로드**
    
    - [MovieLens Latest Small Dataset](https://grouplens.org/datasets/movielens/latest/) 공식 페이지에 접속합니다.
        
    - `ml-latest-small.zip` 파일을 클릭하여 다운로드합니다.
        
2. **데이터 파일 배치**
    
    - 다운로드한 `ml-latest-small.zip` 파일의 압축을 해제합니다.
        
    - 프로젝트 내에 `app/data/movielens` 경로의 폴더를 생성합니다. (`data` 폴더나 `movielens` 폴더가 없다면 직접 만들어야 합니다.)
        
    - 압축을 푼 폴더에서 가장 중요한 두 파일, `movies.csv`와 `ratings.csv`를 찾아 방금 생성한 `app/data/movielens` 폴더 안으로 복사하거나 이동시킵니다.
        
    - 최종적으로 아래와 같은 파일 구조가 되어야 합니다.
        
        - `OTT_recommend/app/data/movielens/movies.csv`
            
        - `OTT_recommend/app/data/movielens/ratings.csv`
            

---

### **2단계: 시스템 빌드 및 데이터 구축**

모든 설정이 완료되었습니다. 이제 데이터베이스를 활성화하고, 필요한 데이터를 채워 넣어 추천 시스템이 작동할 수 있는 상태로 만듭니다.

#### **2.1. 데이터베이스 서버 실행 (`docker-compose`)**

Docker를 사용하여 PostgreSQL 데이터베이스 서버를 간편하게 실행합니다.

1. **Docker Compose 실행**
    
    - 프로젝트의 최상위 폴더(`OTT_recommend`)에서 터미널을 열고 아래 명령어를 입력합니다.
        
    - 이 명령어는 프로젝트 루트의 `docker-compose.yml` 파일을 분석하여, 정의된 서비스(PostgreSQL 데이터베이스)를 백그라운드(`-d` 옵션)에서 실행시킵니다.
        
        Bash
        
        ```
        docker-compose up -d
        ```
        
    - `Creating ott_recommend_postgres_1 ... done` 과 같은 메시지가 출력되면 데이터베이스 컨테이너가 성공적으로 생성되고 실행된 것입니다.
        
2. **컨테이너 실행 상태 확인**
    
    - 아래 명령어를 통해 현재 Docker에서 실행 중인 모든 컨테이너의 목록과 상태를 확인할 수 있습니다.
        
        Bash
        
        ```
        docker ps
        ```
        
    - 출력된 목록에서 `ott_recommend_postgres_1` 이라는 이름의 컨테이너를 찾고, `STATUS` 항목이 `Up`으로 표시되어 있는지 확인합니다.
        

#### **2.2. DB 스키마 생성 및 데이터 적재**

실행된 데이터베이스는 아직 비어있는 상태입니다. `init.sql`을 통해 테이블 구조를 만들고, `populate_db.py` 스크립트로 MovieLens 데이터를 채워 넣습니다.

1. **데이터 적재 스크립트 실행**
    
    - 아래 명령어를 실행하여 데이터 적재 스크립트를 구동합니다.
        
    - **스크립트 내부 동작**:
        
        1. PostgreSQL 데이터베이스에 연결합니다.
            
        2. `init.sql` 파일에 정의된 `CREATE TABLE` 구문들을 실행하여 `user`, `movie`, `rating` 등 모든 테이블 스키마를 생성합니다.
            
        3. `app/data/movielens/movies.csv` 파일을 읽어 `movie` 테이블에 영화 정보를 적재합니다.
            
        4. `app/data/movielens/ratings.csv` 파일을 읽어 `rating` 테이블에 평점 정보를, `movie_lens_data` 테이블에 사용자 정보를 적재합니다.
            
        
        Bash
        
        ```
        python -m app.backend.scripts.populate_db
        ```
        
    - 터미널에 "데이터베이스 테이블 생성 시작...", "movies.csv 데이터 적재 중..." 등 진행 상황이 순차적으로 표시됩니다. 데이터의 양에 따라 수 분의 시간이 소요될 수 있으니, "모든 데이터 적재 완료" 메시지가 나올 때까지 기다려 주세요.
        

#### **2.3. 기본 OTT 플랫폼 목록 등록**

추천 시스템이 인식하고 분석할 대상 OTT 플랫폼의 목록을 `ott_table`에 미리 등록합니다.

1. **OTT 등록 스크립트 실행**
    
    Bash
    
    ```
    python -m app.backend.scripts.register_otts
    ```
    
    - 터미널에 `✅ 'Netflix'이(가) 새롭게 등록되었습니다.` 와 같은 메시지가 출력되며, `OTT_PLATFORMS` 리스트에 정의된 OTT 플랫폼들이 DB에 저장됩니다.
        

#### **2.4. (선택) 전체 영화 OTT 정보 업데이트**

DB에 저장된 모든 영화에 대해 Google 검색을 수행하여, 현재 어느 OTT 플랫폼에서 스트리밍 서비스를 제공하는지 확인하고 그 결과를 `movie` 테이블의 `ott_list` 컬럼에 업데이트합니다.

⚠️ **중요**: 이 스크립트는 DB에 있는 **모든 영화의 수만큼 Google API를 호출**합니다. Google API의 무료 할당량(일반적으로 하루 100회)은 매우 적으므로, 전체 데이터를 업데이트하는 데 엄청난 비용이나 시간이 소요될 수 있습니다. **테스트 목적으로는 실행하지 않거나, 스크립트 내부의 반복 횟수를 5~10회 정도로 대폭 줄여서 테스트하는 것을 강력히 권장합니다.**

1. **OTT 정보 업데이트 스크립트 실행**
    
    Bash
    
    ```
    python -m app.backend.scripts.update_ott_info
    ```
    
    - 실행 시, 터미널에 영화 제목과 함께 검색 결과가 실시간으로 출력되며 DB가 업데이트됩니다.
        

---

### **3단계: 서비스 실행 및 추천 받기**

모든 데이터 구축이 완료되었습니다. 이제 사용자가 직접 서비스를 체험할 차례입니다.

#### **3.1. Streamlit 애플리케이션 실행**

1. **Streamlit 서버 실행**
    
    - 아래 명령어를 통해 웹 애플리케이션 서버를 실행합니다.
        
        Bash
        
        ```
        streamlit run app/frontend/app.py
        ```
        
2. **서비스 접속**
    
    - 서버가 성공적으로 실행되면, 터미널에 다음과 같은 메시지와 함께 URL이 표시됩니다.
        
        ```
        You can now view your Streamlit app in your browser.
        
        Local URL: http://localhost:8501
        Network URL: http://192.168.x.x:8501
        ```
        
    - 사용하시는 웹 브라우저(Chrome, Edge 등)를 열고 주소창에 `http://localhost:8501` 을 입력하여 접속합니다. OTT-Navi 서비스의 메인 화면이 나타날 것입니다.
        

#### **3.2. 추천 워크플로우: 설문부터 최종 결과까지**

1. **[시작 페이지]**
    
    - 서비스의 목적과 기능을 소개하는 첫 화면입니다. 하단의 "나만을 위한 추천 받기" 버튼을 클릭하여 개인화 추천 프로세스를 시작합니다.
        
2. **[1단계: 기본 정보 입력]**
    
    - **사용자 입력**: 성별, 연령대, 현재 구독 중인 OTT 등 개인의 프로필과 관련된 질문에 답변합니다. 각 항목은 드롭다운 메뉴나 버튼으로 구성되어 있어 편리하게 선택할 수 있습니다.
        
    - **백엔드**: 이 단계에서는 입력받은 값을 변수에 임시 저장하기만 합니다.
        
    - 모든 항목에 답변 후 "다음" 버튼을 클릭합니다.
        
3. **[2단계: 영화 선호도 조사]**
    
    - **화면 표시**: DB에 저장된 영화 중 인기와 평점이 높은 영화들의 포스터가 무작위로 화면에 나타납니다.
        
    - **백엔드 동작**: 이 화면이 로드될 때, `crud.get_movies_for_survey` 함수가 DB에 요청을 보내 설문에 사용할 영화 목록을 가져옵니다.
        
    - **사용자 입력**: 표시된 영화들 중에서 과거에 재미있게 봤거나, 보고 싶다고 생각했던 영화를 **최소 5개 이상** 자유롭게 클릭하여 선택합니다. 선택된 영화는 화면 한쪽에 리스트로 표시됩니다.
        
    - 이 단계는 사용자의 초기 영화 취향을 파악하는 가장 핵심적인 과정입니다. 선택을 마쳤다면 "내 취향에 맞는 OTT 추천 받기!" 버튼을 클릭합니다.
        
4. **[분석 중... 로딩 화면]**
    
    - "추천 받기" 버튼을 클릭하는 순간, 백엔드에서는 복잡한 추천 로직이 가동됩니다.
        
    - **핵심 백엔드 동작 상세**:
        
        1. **사용자 정보 저장**: 지금까지 설문에서 응답한 모든 내용(`기본 정보` + `선호 영화 목록`)이 `crud.create_user` 함수를 통해 DB의 `user` 테이블에 하나의 레코드로 저장됩니다. 이때 고유한 `user_id` (UUID)가 생성됩니다.
            
        2. **'가상 아바타' 찾기**: 방금 저장된 신규 사용자의 `선호 영화 목록`과, DB에 있는 수많은 MovieLens 사용자들의 `시청 영화 목록`을 비교하여 **Jaccard 유사도**를 계산합니다. 이 중 가장 유사도 점수가 높은 MovieLens 사용자를 신규 사용자의 취향을 대변할 '가상 아바타'로 지정합니다.
            
        3. **평점 예측치 로드**: '가상 아바타'가 아직 시청하지 않은 영화들에 대해, 미리 학습된 딥러닝 모델이 예측해놓은 평점 데이터(`rating` 테이블)를 모두 불러옵니다.
            
        4. **영화 목록 생성**: 예측 평점이 높은 순서대로 영화를 정렬하여, 상위 50개의 영화를 최종 추천 목록으로 확정합니다.
            
        5. **최적 OTT 분석**: 이 50개 영화 목록을 `crud.get_recommended_movies_with_ott` 함수에 전달합니다. 이 함수는 각 영화의 `ott_list` 컬럼을 확인하여, 어떤 OTT가 이 50개의 영화를 가장 많이 서비스하는지 (예: 넷플릭스 18편, 왓챠 11편...) 집계합니다.
            
        6. **추천 결과 확정**: 집계 결과 가장 많은 영화를 보유한 OTT를 "최적의 플랫폼"으로 결정하고, 추천 영화 50편의 목록과 함께 프론트엔드로 전달할 준비를 합니다. `crud.increment_ott_recommendation_count`를 호출하여 해당 OTT의 추천 횟수도 1 증가시킵니다.
            
    - **사용자 경험**: 위 과정이 진행되는 동안, 사용자는 "AI가 당신의 취향을 분석중입니다" 와 같은 메시지와 함께 로딩 스피너를 보게 됩니다.
        
5. **[최종 추천 결과 페이지]**
    
    - 모든 분석이 완료되면, 사용자는 자신의 취향에 맞춰 생성된 최종 추천 결과를 한눈에 보게 됩니다.
        
    - **최적 OTT 추천**: 화면 상단에는 "당신에게 가장 적합한 OTT는 바로 **[왓챠]**입니다!" 와 같이 최적의 OTT 플랫폼이 추천 이유(예: "추천 영화 50편 중 16편을 시청할 수 있어요")와 함께 가장 먼저 표시됩니다.
        
    - **개인화 영화 추천**: 그 아래에는 추천된 영화 50편의 포스터, 제목, 예측 평점이 그리드 형태로 보기 좋게 나열됩니다. 사용자는 스크롤하며 자신이 좋아할 만한 새로운 영화들을 탐색할 수 있습니다.
        

---

### **4단계: 문제 해결 가이드**

프로젝트 실행 중 발생할 수 있는 일반적인 오류와 해결 방법입니다.

- **오류: `ModuleNotFoundError: No module named 'backend'`**
    
    - **원인**: 파이썬이 `backend` 폴더를 라이브러리(모듈)로 인식하지 못하는 경우입니다.
        
    - **해결**: 스크립트를 실행할 때 `python [파일명].py` 대신 `-m` 옵션을 사용하여 모듈 형태로 실행해야 합니다.
        
        - (오류) `python app/backend/scripts/register_otts.py`
            
        - (정상) `python -m app.backend.scripts.register_otts`
            
- **오류: `sqlalchemy.exc.ProgrammingError: (psycopg2.errors.CannotCoerce) cannot cast type integer to uuid`**
    
    - **원인**: SQLAlchemy가 DB 세션을 관리하는 방식과 코드의 흐름이 맞지 않을 때 발생합니다. 특히 UUID를 기본 키로 사용하는 테이블에 데이터를 추가하고 즉시 그 객체를 다시 사용하려고 할 때 자주 발생합니다.
        
    - **해결**: `crud.py` 파일의 관련 함수(`get_or_create_ott` 등)에서 `db.commit()`과 `db.refresh()` 대신, `db.flush()`를 사용하여 트랜잭션 내에서 객체 상태를 동기화하는 방식을 사용해야 합니다. 이 가이드 상단의 `crud.py` 코드를 참고하여 수정하세요.
        
- **오류: Docker 실행 시 `Error response from daemon` 또는 `Cannot connect to the Docker daemon`**
    
    - **원인**: Docker Desktop이 정상적으로 실행되지 않았거나, 실행되었지만 시스템이 인식하지 못하는 상태입니다.
        
    - **해결**: Docker Desktop을 완전히 종료한 후 다시 실행하거나, 컴퓨터를 재부팅해 보세요. Windows의 경우 관리자 권한으로 실행하는 것이 도움이 될 수 있습니다.
        
- **오류: Streamlit 접속 시 "Connection error" 또는 "데이터베이스에 연결할 수 없습니다"**
    
    - **원인**: Streamlit 애플리케이션이 데이터베이스 서버를 찾지 못하는 경우입니다.
        
    - **해결**:
        
        1. `docker ps` 명령어를 통해 PostgreSQL 컨테이너가 `Up` 상태인지 다시 한번 확인하세요.
            
        2. `app/backend/db/database.py` 파일에 하드코딩된 데이터베이스 연결 주소, 사용자 이름, 비밀번호 등이 `docker-compose.yml` 파일의 `environment` 섹션에 정의된 값과 정확히 일치하는지 비교하고 확인하세요.